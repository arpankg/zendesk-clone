%START_METADATA%
Class_Name="Class 6 - LangGraph"
Class_Date="2025-01-22"
%END_METADATA%

Speaker A

There you go. All right, thanks, Aaron. Back off to you. And we're going to be making the thread as we always do and keep adding your topics in the Zoom chat if there's anything else.
Speaker B

Thank you. I've got the question thread and I'll put my eyes in that. That's the best place for questions for me to see. Excited to talk about the topic today, which is Lang Graph, which is a very powerful general that enables building a variety of patterns, using large language models and using really other code as well. So let's get to it. All right, assuming you're seeing my screen here, go ahead. So Lang Graph, like most of the libraries we've been looking at, is part of LangChain and I will there are of course alternatives in this space, but we very much recommend focusing on this, at least initially. And what Lang Graph is providing is it's a framework that will let you basically use a graph to coordinate or execute LLM agents or chains or really just LLM things, as well as whatever other general logic you wish to code that can become part of that system and it lets you put it in a graph structure, which I imagine everybody has at least some familiarity with. But if you're not super into data structures and such, the, the mental model you want to have here are nodes and edges. Sometimes nodes are also called vertices or vertexes. But I'll probably try to stick to nodes and edges for my language where a node is a dot in the visualization and an edge is a line. And in what we're making the, the dots as it were, the nodes will be things like LLM agents or just, or code in general, that's where sort of like execution happens. And then the edges represent messages being passed containing state from some node to some other node. And these edges and these nodes can be connected pretty much arbitrarily. Now that there, that said, that's a, that leads to a huge potential space. So you don't want to just go nuts. There are some patterns. We're going to show you you of typical ways that these graphs can be built for this domain. But this is an area where you could potentially tweak things or come up with your own approach as well. So what are we getting out of this? Well, we're going to learn the components of an AI graph, the value of state, some cases for it, and comparing this a little bit to some of the other techniques we've learned about multi agent graphs and then a few other more advanced I, I refer really to all the four through six here as different design patterns, sort of borrowing from the language of software design patterns for anybody familiar with that, from object oriented programming. So different design patterns with LLM graphs that could be suitable for you, an application you're working on, or at least could be a source of inspiration for you. So this is what a graph looks like here. And to be clear, this is just a particular example graph and we'll talk through what it's doing specifically. But you can see there are nodes and the nodes here are the dots and the edges are the lines and then there's a little bit more going on here. But. But actually it sort of visually is, is helping break it down. These red indicators basically are. You can think of them as either nodes that are really simple, that are basically just if statements or you could think of them as just a visualization of a conditional edge. So this edge will then go here and then go left or right, you know, based on the state being passed into it. And this is just a visualization of the state being passed here. Technically you'd have an object like this being passed along all the lines. We're just showing it here. So let's talk through what this system is actually doing here. We see the entry point and this is a fairly typical pattern for it because a lot of the power of LLM is that hey, you can take natural language questions, natural language instructions and input. So often the input looks like something like this. But you'll see there's also this input here. So this is implying, hey, maybe there's also a RAG query that is feeding some documents to the first node as well. So you've got a few inputs and we'll get to this last input later. And the idea here is we're going to be asking it to say write some code. So you were asking it to write some LangChain code and it generates something and we have it structure the output so it fits in the schema of the state that we expect to be passing along the edges. And so in this case that means we have the actual coding logic, we have the imports separated out and then we have preamble. You can think of that as like readme human human facing documentation summary or LLM facing actually. Right, but natural language summary that gets passed here. And what this node is doing is it's checking all the imports. It's going to actually and this to be clear, this is just an example. So it's a little open ended what you'd really do here. But I think one good way to do it would be to actually try the imports, right? Have some sort of system set up that can verify that the imports are real and valid and work. And if they fail, we pass a stack trace and that's where we get back here, looped back to the generation and we basically say, you know, hey, we tried to run this but we couldn't import this and fix it, right? And so then the generation node will try again and eventually at some point when it gets past the import check, all the imports are good, there's an actual code execution check. And again, what this is would be a little bit context dependent, but a loose sketch of it could be a. Something that fires up a test suite on all the code and make sure there haven't been any regressions on the tests or at the very least something that just runs this code and make sure there's no syntax errors, right? Like make sure this code parses and doesn't die automatically. Whatever this check does, if it fails, it's also going to result in some stack trace, some message or something that's going to go back, try again, and if it passes, we're happy, we're done. And then this here is the exit really. This is the. Sorry about that. The actual answer that will go out to the user, which will probably contain all of these things. It'll, it'll describe what it is and then say here's your code, here's your imports. But, and yes, I see the question, I'll get to it in a sec. And the thing that I, I also emphasize about this end to end interface here is user facing wise. This is basically the same interface as just zero shotting with an LLM, right? So what I mean by that is if you just go to chatgpt.com you ask your question, you get your answer, right? And if you say, hey chatgpt, write me some Python code with, with imports and a preamble that you know, whatever does stuff, you're going to get your response. But what we're adding here is this sort of self ref. And yeah, to the, to the checks, exactly. The idea is the check is probably going to be, if not, if not an LLM, then at least some programmatic check. So some automatic check, right? You're, we're. There is such a thing as human in the loop and we'll talk about that at some point, I'm sure. But a lot of what we're seeing here today, the idea is these nodes are going to be code, which certainly could involve sending this to another LLM with another prompt saying, hey, check this. In this particular example, I feel like you wouldn't want to pass it to an LLM to check because the idea is to see if the code actually runs.
Speaker A

So.
Speaker B

So if this is Python code, you're probably passing it to Python, really. But there could absolutely be cases. We'll see some cases. Yeah. And Ash has got a good answer on the thread too, so. But yeah, that's the idea here, is that even though there's a lot of complexity, the user interface is as simple as chat is as simple as the regular chat GPT interface. And all this just becomes a bit of a more complicated black box to them. But obviously we're the ones building some boxes, so we need to know what's going on inside. I'll leave this up for a moment longer just because I think it's, it's a good summary of what we're doing and I'll see another question coming in. All right, well, all right. I vaguely understand that you have functions and data that gets piped. I'm having trouble understanding what is this? Why is this as opposed to say, a set of function calls? It comes from the graph structure. I mean, in a sense you could model this as functions. Really all of this is our way of modeling a system. The question that came up before, we need more system architecture. Well, system architecture is mental models applied to complicated technology. Could you say, oh, at the end it's all just assembler. Why are we modeling anything? Right, like it's all just electrons on silicon or something, but having these abstractions, having these models with, you know, in this case we're using a graph, we're using nodes and edges. But having that model to let us build our understanding and let us design the system and the code will correspond to this too. Of course. This is the language that we'll see in the high level code we're using. And yeah, we will see a lot more examples in the remaining slides. So I will leave that to the slides. Although this, I would say is already an example. If you wanted to write a code generating system that had self checks, that's perhaps kind of valuable, right? Like you, you don't want hallucinations or syntax errors in your code. You want those to be checked and fixed automatically. But we will see more examples too. So a little bit. Well, cursor, kind of cursor has a human in the loop though, right? You all were doing this with cursor. The idea though is that this system would just do it, right? And I guess maybe the agent does actually have some implicit graphs. The agent is a little bit more self managing, but still there's a lot of human in the loop. In any case, we'll see more examples too, but exactly cursor could be thought of at least cursor agent could be thought of as somewhat graphy. I still think of cursors mostly with a human involved too though. Anyway, state. So state is represented typically as a dictionary, which again for the people who are not Pythonistas. Jason Blob Key value pairs, right. Dictionaries though are a nice way to represent it. And you'll see Pydantic, which is a Python type system. You'll see that in a lot of this sort of code in this ecosystem. Also when you expose APIs with these things and what the state has to have is it has to have all the information that is going to be passed from node to node. Because the whole point of this structure, if nodes didn't pass anything, it wouldn't be a graph. If nodes just did their work then, then you're, then that's just something doing some computation. It's a graph because you have nodes passing the results of their computation back and forth. They're potentially loops. So there were a few loops here, right? And you see an explicit loop here. A loop is whenever you potentially can just go round and round. And as you can probably intuit, this can mean that the computation time can be arbitrarily long. Now with Lane Graph, I believe there's a default recursion limit of 5 or 10 or something. And that's the sort of parameter that you can also set if you're concerned about your system truly just going forever. But even if you have a limit, graphs are a good example of something that like this is going to take longer to compute than just sending something to an LLM and getting it back, or certainly than running non LLM code most of the time. And so this also, you know, back what we said Monday about, about asynchronous execution, you might, if there's a situation where you have some graph stuff going on, you might want to look at Async so that it's not blocking on everything else. Anyway, so this state, often the typical pattern you'll see, this is like the schema for what's being passed on every edge. And at the beginning it will mostly. The message like this will mostly be unpopulated, it'll kind of be empty, right? And then it'll get populated field by field by the nodes as you go and Those fields, the populated fields, will also be used by the nodes to make their decision. So the query will go in here to the browser and the editor, and the browser and the editor are probably going to, you know, talk about what sections should be written. This is a research state, a research paper writer. Right. And then there's this loop where I want to talk about the loop. It goes to the researcher. The researcher will have, say, actual Internet access, some tools to search the Internet and will find research data, which we're representing here as a list of more blogs. So all sorts of stuff that goes to a reviewer and a reviser and if they're not happy with it, it goes back to the researcher who would then update, find more research data. Right. And this could potentially keep going for a while, depending how you prompted and designed it, until eventually you have all this sort of structure and research data populated. And that goes to the writer that actually writes the report itself. Right. And also presumably the conclusion, introduction and stuff. So, so the idea of this system is instead of just asking an LLM to write a paper, we are having a number of steps that are going to gather information and update that information until it's satisfactory to make a good plan and a good structure and have good research information and then pass that finally to a, to an LLM prompt that will actually write the paper. But chances are most of these nodes are going to involve some LLM, not necessarily to like, only this one's the only one doing a lot of writing, but to do other logic to, to search the Internet, to do things like that. To the question, I thought of this as a state machine. I mean, state machines can, can be a model for almost anything. Yeah, you can think of this as a state machine where the state change is basically following one edge or another edge. I think that the graph representation is useful visually. And again, it's also going to be the language we'll see in the software framework itself. But yeah, I think you're coming at this from a reasonable direction and you'll continue getting understanding as we see the actual code too. So revisors are LLMs with certain rules. Well, again, this is just a sketch. We haven't actually implemented fully every node and how you implement it would impact how reliable it is. But yes, the idea that I would see here is that the reviser and the reviewer would be LLMs that are given the output from the earlier steps and are told like, hey, you know, review this for this sort of issue and then, hey, fix these sorts of issues and then decide Whether or not we need to get more resources or it's fixed enough for the writer to do what they should. But yeah, each of these nodes can be LLMs a super prompt. Well, I mean I, I think of it as separate individual prompts and, and that's what makes this so powerful. As you've all probably discovered, if you try to cram too much in a prom, sometimes overwhelm the LLM. And so even if these are all the same actual model, these are all just calls to GPT4O mini or something, they're going to be prompted differently, they're going to have different contexts, they could potentially have different hyper parameters if that's suitable for you. And I'm not going to like, I'm not, I think browser, I'm not sure that browser is an LLM here. I'd have to think about that one more. But certainly a lot of these capital ones most likely are in this case. And yeah, the multiple prompts with different input will really change how they behave. All right, keep moving here because I think these questions will continue to be relevant with the oncome ongoing slides. And yeah, as Ash said, you know, you could have, these could each have their own rag, they could have separate retrievers, they could be different models. Absolutely, yeah. And part of the, part of the good News is the OpenAI's API format has become a little bit of a de facto standard. So even if you develop against OpenAI's API, it's not too hard to port that or to use that with something that is self hosted or via some other service. All right, so comparing a little bit, and while we compare, I also want to emphasize all this stuff is composable. I mean, you all write code, you know what I'm talking about here. You know, you can have classes within classes and functions within functions. Right? Well, you can do the same thing with all this. You could have a graph where one of the nodes is a chain, say. Right. Or a chain that occasionally kicks off a graph for some reason or whatever. Again, as I've said a few times, don't just do that for giggles, do it if and only if it's truly reflective of the complexity of the problem you're trying to solve and it's the right structure for what you're doing. Always use the simplest approach that's going to work, especially while you're getting started. But really just in general, that said, that's what's so powerful here. The, the incredible flexibility and that's, that's emblematic in particular. Of graphs. So chains, as we discussed on Monday, are these sequential execution structures. You could think of a chain as a subset of a graph. A chain is a graph where it's just node to node to node to node, with one edge along each link. Right? So a chain is a graph. But I mean, a chain is a special case that is particularly common in something like a data pipeline. It's a graph that only goes one way. Graphs, by the way, have subtypes. Does anybody know the name for a graph that only goes one way? It's more general than chains. Diagraph Close. Or may. Maybe I, I, I think, yeah. D Directional graph directed acyclic graph. Exactly. So, and you've been using that every time you've been using git. So that would be a graph that doesn't have these loops. And it's still more flexible than a chain. It can still have forks just like you can have branches and git. But a DAG can be a very useful structure and sometimes it's a very useful restriction to say, hey, no loops. Of course, sometimes you might actually want the loops. You want the system to be reflective and you're able to structure around it to make sure that the time it spends doing that is in some way limited. So it doesn't just spin forever. But the point is, is that there's all these different structures you can do with graphs that are more complex than chains. And then agents, again, you could think of an agent as essentially the LLM making the decisions. So, and the LLM being given more flexibility perhaps than just like left or right on a graph, but the LLM actually being given a suite of OP options and deciding what comes next. So really I would actually say to that question about cursor. Cursor is less of a graph and more of an, of a human. Well, an agent. Right. The agent mode is right there in the name. In agent mode, it's acting like an agent. And of course it's still an agent that has at least some human in the loop, which refers to the fact that it will ask your permission, for example, before running certain things. And this is good because what if it accidentally ran RM-RF, right? So you, you often want human in the loop with agents because of how powerful they are. In a sense, they are the most general because they're not even limited by any structure. They just sort of quote, do what they want or at least within the realm of the tools and the options that they are given. And there's no prescription or limit when they choose what they choose based on the step of the problem they're facing as, as they see it. So, and I, I want to also, whenever I talk about agents, I feel necessary to give a slight caveat. It's convenient to talk about them with, with language like they. Right. And they decide it's 59 degrees in here. Somebody's muted, by the way. Unmuted.
Speaker A

I mean, I just muted them.
Speaker B

Great, thanks. So, you know, whenever, whenever we talk about agents, it's very natural to, to anthropomorphize them. That's the fancy way to say, to treat like a human, to use language like, oh, they, they see, they think. And that's because that's the most convenient way to describe what we observe and what we're interacting with. That is. Again, I'm not going to philosophize fully because we have a lot of ground to cover here. But from a technical perspective, I just want to remind all of us that that is not at least what is happening in any way we understand it. That is not the internal model of them in any way comparable to us, at least consciously. They're still very cool. I'm not ragging on them at all here, but when you anthropomorphize your tools too much and get superstition about them, you're not going to build as reliably with them. You're not going to understand them and be on your toes and know their limitations. So they're not magic. And whether or not they are conscious, I will leave to people to philosophize some other way. But just be careful when you anthropomorphize them. Now that'll hopefully be the main time. I give this caveat as we talk about agents, but they are very cool. So few other questions, but they look like they're all handled. Agents can choose which nodes. I mean, with agents, there maybe aren't even nodes. Agents can just choose their actions based on whatever actions are made available to them. And we haven't fully introduced agents. So I, I would, I would say think of cursor agent for now, where it's like it can write code, it can run shell commands and like run shell command is a pretty general tool. Right. There's a lot of things you can do with that. As is right code. Exactly. The decision making is the. But exactly the LLM instead of having any sort of logic that says, oh, we've got edges on a graph and you know, there's a condition that will make the edge fork based on such and such Instead of that, it's entirely the LLM making the decision. And you might say, oh well, the LLM is kind of making the decision here too. But it's subtly different in that we're making the decision a single yes, no decision based on the output of the LLM. And that is different than an agent which is not just single yes, no decisions guiding a graph, but is actually like gets to choose between all the options every time. Whereas with graphs you can structure and you can basically direct it more. So I would say ultimately agents are actually the most flexible. The least, not, not the least structured. Exactly. But like the least pinned down. Chains are a subset of graphs and graphs are a useful representation of all sorts of things. You can represent social relationships, you can represent knowledge, you can represent flowcharts and processes. There's lots of things you can represent with graphs. And so if you can represent something with a graph and if some of those things can be automated by LLMs, that becomes a candidate for an, for a LLM system to automate something and to, to have a useful product of some sort. So that's the way I would start seeing this. It's like think about graphs as they apply to the world and then think about, hey, what if I could automate it? All right, keep the questions coming, but I'm going to get to these few examples and there's also some code. If we have, if we have time for all of it, we'll get to at least some of it, I think. And we're getting here to the part that I would say are the design patterns of, of graphs that we're showing. And if you're unfamiliar with what I mean by design patterns that you've ever heard of the, of a factory, right, which is a function or method that can instantiate objects. That is a software design pattern from a book of software design patterns from like the 80s or something. Right. So what are the patterns? What are the typical things that we might do to organize our graphs since they are fairly open ended? Well, one of them is to have multiple agents and the graph essentially mediates their contributions and interactions. So the user asks their question, generate a chart of average temperature in Alaska and that is set up in the graph to first go to one agent, a researcher. And this researcher will have particular tools of like search the Internet, get some data, these sorts of things. But they're an agent so they can kind of just make their own decisions to solve this problem within that, within what they have, then the router here is what will take their Request and they're either going to say, hey, I need to run a tool and use that, that'd be like search the Internet and use that to continue working, in which case we loop back or hey, I'm done, I've done all my research, I've got everything. In which case it gets routed to the other agent and the other agent is the one that will actually try to resolve the user query to generate the chart, but also has the information, the output from this agent. And they too can say, hey, I need to run a tool, I need to, I need to run some code or see something. And then when they're happy, they'll say, hey, I'm done and final answer. And if they're done, done, then it goes back to the user. Or they could say, hey, there's not enough data. Send it back to the researcher and it goes back to the researcher. And part of the purpose of this sort of pattern, you could imagine how with more nodes and edges, you can have more agents and more conditions for how things are passed between them. And we'll see examples like that. But you know, we've been talking about how general agents are and how, how powerful and flexible they are as well. But that actually is a source of danger really. And I don't mean in the AI safety sense, I mean more like just in the software engineering your code doesn't work. Since if, if you have something that is extremely capable and you try to give it every tool, like why do we have two agents here? Why don't we just have one agent and we give it search and we give it code and I mean, honestly, this problem is simple enough, that would probably work okay. But the more tools you give an agent and the more options you give an agent, the more likely it is to be confused. Like imagine if the cursor agent wasn't just writing code and running command line tools, but it could also do like you know, five other things, right? Then it has all the, a larger surface area of decisions and tasks to focus on. And it's more likely to mess up. I mean, a human's more likely to mess up in that situation too. You know, all decision making agents are going to function better when there is more focus, when there's a more limited problem space. And splitting up multiple agents with a graph structure allows the agents to be more focused, to have narrower problem spaces. And then it's up to the graph structure and whatever, whatever other logic you're coding to actually combine it all, put it together in a way that makes Sense for the problem you're trying to solve. Again, this is just a particular example of that. But the general idea is it can be very useful to encapsulate several agents in a graph rather than like saying, oh, the system is an agent and it's just a single agent. And this agent somehow does everything that's in many situations just not going to be a very reliable or good system. And you'll want to add a little bit more structure to be able to get it where you want to get it. All right, there's some questions coming. Yeah. Agents also get analysis paralysis. Yes, that's a good way to put it. And I think the other question in there, Ash is probably answering, so I'll. I'll let him do that. Thank you. So what's a general pattern if we want to scale to even more agents in our graph? Well, there's the supervisor pattern. And this looks almost like an org chart, doesn't it? So it's just an interesting parallel. Again, be careful anthropomorphizing your agents. But we have here multiple agents, and in this case they each have different specializations. This could be a research agent, and this could be a coding agent, and this could be a documentation agent. I don't know. You could build your whole team here. Right. And then you have a supervisor. So the supervisor's job is to be the interface. You see, the user only ever interact with the supervisor. And by the way, the end to end interface that the user is going to see here is basically going to be the same as the one they saw here. They give a question, stuff happens, they get an answer. Like the LLM interface at the top level for the user is pretty pretty much usually pretty constant. Right. You could have different systems, but a lot of the patterns are going to look like this. But in this case, what that black box is doing is the user gives their request and again, say these agents are specialized to be different roles of a software development team, like a technical writer and a coder and a qa, something like that. Right. And the user gives a software development task, you know, develop and test a tic tac TOE application. I'm not sure why you'd want that, but you could ask for whatever. It's up to the supervisor then to basically take this task and figure out which agent it should go to first. Right. And then route the task to the agent and the agent works on the task and updates whatever else. We're not picturing the state dictionary here, but there would be a state dictionary that would probably have, for the purposes of software development, it would have like files or code or directories with files and code in them and maybe some other state that is relevant to whatever particular problem you're solving. And the agent that it's assigned to, it assigns to the coder. Agent first, say, would write some code, update stuff and when they're done, return it to the supervisor. The supervisor then looks at the updated state and decides what to do next. And their decisions could be routed to agent again or give it back to the user and they might say, oh well, there's code, but it needs to be tested. So they pass it to the QA and then they get it back. No, there's code, but it needs some documentation. So they pass it to the technical and they get it back. You can. And by the way, what's nice about this pattern versus this pattern, this one, if you're going to add a new agent, you'd have to think a little bit about your routing rules or, you know, it would change the graph. Basically this is a two agent graph, the way it's written. And anything else would just be a different graph. This pattern scales horizontally pretty well in the number of agents because if you add another agent, it would just be another leaf. Agents are always leaves and they always have two edges back and forth to the supervisor. And that's it. That's it for this supervisor pattern. That's the way you would expand it. So you could potentially add arbitrarily many agents and the supervisor would be the one mediating all these connections. And eventually when the agents have done their work again within the judgment of the supervisor. And when I say the judgment, what I really mean is within the prompting you gave the supervisor. Right. Within how this is set up in terms of whatever system prompt and whatever information, whatever other context it's being given, eventually this will reach the decision that, okay, we're done. The agents have, have updated the state to a satisfactory condition. I'm going to pass the results back out to the user. And this is again really a pretty general pattern. I talked through it as a software development thing, but anything that a team works on could potentially, you know, you could try to automate it with this. And that's pretty cool. That's pretty powerful. It's interesting how this looks like a human team structure. So few other questions coming in. Yeah, so exactly. A lot of the magic here. Frameworks are going to handle things like timeouts or recursion limits. You, you might need to actually look up and set some details if you're really building production grade systems, so you can't just completely ignore it, but in terms of developing it, you, there are accommodations for that. What does Perplexity do? I'm not, I mean, we don't work for Perplexity and they're not open source. But I feel like it's more of a rag than a supervisor agent pattern. And maybe there are some tools for particular things. Certainly if I was building an information retrieval system, which is what Perplexity is, I would want it to have tools that handle things that LLMs are bad at. So it should be able to recognize when something's a math problem and just go use Wolfram Alpha. Right? Like just don't try to solve it yourself. LLM, you're not meant to do this, that kind of thing. So I would think it's probably just a single agent, but they could have a graph going on over there. All right, gonna go on to the next example. So you know, I was saying, hey, how do you scale this out? Well, you can just add more agents horizontally here and add more lines, but at a certain point, you know, just like human managers can't really effectively manage more than pick what number you want. But let's say 10 direct reports. These LLM supervisors, if you give them way too many agents as options, they're also going to be suffer from some of that analysis paralysis. Or at the very least just there'll be more randomness, more stochastic behavior, and less reliable output in terms of the assignment of tasks, simply because there's more options. Right? Like okay, if you have a hundred agents reporting to you, then assigning your tasks, splitting them out, getting the results back and forth just becomes a more random, brittle, difficult process. So if you have, if you really wanted to build a system with that many agents, or even say 20 or 15 or something, or you might want to split it out. And that's what this is showing. And it's just hierarchical. And again, we're looking even more like an org chart here where the user is still end to end, text to text, interact with the supervisor. The supervisor though does not route to the individual contributors to the LEAF agents. The supervisor routes to what we could call team managers, if you will, or team leads. And these function a lot like the supervisor did back in the prior pattern. But they have a particular domain. You know, this domain is research, this domain is documents and writing. You have one with the domain of software development, etc. And then that team lead is responsible for the routes back and forth to Try to solve the problem they're given with the actual LEAF agents here that actually do the work. And by the way, I've been saying leaf, if you're not familiar with that, a leaf node is a bottom node on a graph like this. It's, it's a graph node without any children. That's the, that's what it's referring to. We're not going any further down here. So this is just another pattern. I wouldn't jump to this one, but it's, it's good to be aware of as an option if you're building a system that is complicated enough that it might warrant this. And it's again, in a real world situation. Would you use exactly these graphs exactly as they're pictured here? Well, probably not. You know, you're going to be solving whatever specific problem you're solving and there might be little edge cases here and there or other special inputs or other other little things. Right. But that's just like, you know, that's why I'm referring to these as design patterns. Design patterns are blueprints, but not exact recipes. So you would use this as a starting point. But if you end up tweaking it some for problem you're solving, that's fine. So yes to the definition of agent? Well, I would say that Ash, we probably will have other lectures where we dig more into that. So I'm going to try to get through more of this material rather than lose the last 10 minutes on that. But I definitely hear you that that's something to discuss. I do think that part of the reason that it's difficult to define rigorously is it's still something that is so new that at least the casual public usage of it isn't necessarily rigorous. But again, I would, I, I do think that the cursor agent is a reasonable representation. I'll try to give a concise definition that I would consider correct, which is that an agent is an L is a system where an LLM can guide, can make decisions and use tools and tools being other code, other things. So again, think of the cursor agent. It can literally run shell script, right? That is a tool or a lot of these other examples here. A searcher would use a search tool, which is exactly what we're going to get to in the code here. So I don't think this slide is relevant, Ash.
Speaker A

It's if anybody wants to do it.
Speaker B

Okay. If you want to practice thing, here is a, an example graph that you could make where you actually have a loop. You Give user input and you ask to write a report and you reflect on the report and improve the report. And this is a reflection pattern that can improve the quality of the output. So that said, what we'd like to do here first, just look at at least some code. This is MVP lang graph code and all it does, and this is truly mvp, which is to show the imports of the constructs. We have our setup on our connections. We need a model. We instantiate a graph and we're going to instantiate it as a message graph. A message graph is a special sort of graph and lane graph where the state is assum to be messages, like LLM messages. And this means that we don't have to define a schema for the state being passed between nodes because we just assume it's LLM like OpenAI format chat messages, which is kind of convenient. Then we're going to add a single node, which we're going to call Oracle, and a single edge from that node to the exit point, which is a special thing called end, which we also imported up here. So this is the end state. So the question of state diagrams, yeah, you could consider or state machines, you could write a state diagram or consider graphs, a state machine as well. But we set the entry point as Oracle, we compile it and that gives us a runnable. And a runnable is the same really as the model itself, the same as a chain. It is something in lang chain that we're able to give input to and get output. It gives, gives us this interface here. We can run this, we'll give it our question, it will give us a response and then we're going to just ask it, what is one plus one? Which is kind of silly, but just to prove that it's actually doing something. And if we run this one plus one equals two. Now all we really did here was give a single prompt to chatgpt 400 and many. And despite me saying that LLMs aren't good at math, they are able to do one plus one. And it said one plus one equals two. And we printed that response here. But what actually happened was that got passed in the entry point to the Oracle node, the Oracle node sent it to the model, the model got the response for the Oracle node, and then that went to the end node, which is what gave us the actual output. And you can add other nodes and edges, basically you can structure graphs however you want. Right, that's, that's the power of it. But we will look at some of these notebooks here. Let me Also see if they're pre rendered while this is coming up. All right, so what these are, by the way, the first notebook here. Multi agent collaboration is an implementation of this system. The supervisor for the supervisor and the hierarchical team for the hierarchical team. So I'm actually going to skip the multi agent collaboration one in the interest of time you can refer back to that one. I'm going to look at the agent supervisor one a bit and then leave the other two for you as this sort of more complicated and less complicated points. So yeah, so you don't. You. You only need to specify one entry point and you only need to get to the end. Well, potentially your graph could, could have multiple exits. Right. They might be confusing. I think that's typically not what you would do, but you could route to the end wherever you want. The entry point, you should have a unique entry point and yes, so if you want to. It's not that you, if you want to add metadata to the message, well, you just. That's no longer a message. You should just use what's called a state graph, which is what we'll see in the other examples. And a state graph lets you define your own schema with arbitrary, you know, key value pairs to be the message schema that's passed around. All right, so you'll see here we're getting set up and connected, we're importing some tools. So tools again are functions or code that are designed for LLMs to use to further whatever task they're given. And we're getting a Python repl tool which lets you run Python in a repl, a tavily search tool which lets you search the Internet and then just the general constructive tool. And then we're going to make some helpers here. These are some soft, some, some reusable code that you could use when you're making your own system. It's helpful to. This is I would say basically a factory pattern, interestingly enough, to have a function to create agents and we give it the LLM connection, the tools it should have and the prompt that it should have. And it puts all those pieces together. So it puts the prompt into a system prompt and it also makes room for messages and what's called the agent scratch pad. The agent scratch pad are also messages, but not like human messages that we would interact with their space for the agent to basically think out loud or to say what it's doing and to plan. The agent then is based on this import. Create OpenAI Tools agent from LangChain and we give it the LLM connection, the tools and the prompt. And then we have to make an executor which will actually expose the interface we want to put in the graph. So the executor also has the agent and the tools, and that's what we've returned here. And then an agent node will take an agent, we'll take a state, and we'll take a name, and it will invoke the agent on the state, and then it will return basically another state. It will return the messages and the name of the node. So we are adding some metadata here, we're adding what node we're on. And this really is a node. It's kind of weird to think about, but the nodes are something, are functions that take state and return state. That's, that's, that's. I think one of the better ways to think about nodes takes state, return, state. Now it takes state and return state in a way that like it's taking state from a certain direction, returning state in a different direction, but they all take state and return state. And so this general construct, you have to of course, pass the actual agent that's doing the processing. But this will let you make whatever nodes you want. The supervisor needs its own special prompt. And so we give it. This can be even more engineered, but for a basic prompt, we're saying, hey, you're a supervisor, you're managing a conversation. We're going to tell it who it's managing it between, and then given their request, say which worker should act next, if we're done, say, finish. And then there's a bit of structure here that I don't think I'll get to in just a few minutes in terms of fully summarizing. But if you look up OpenAI function calling, what this is, is this is a structure that actually enforces the, the format of the response from the LLM. It's saying that we expect it to give us any of a certain number of options, right? And that this needs to be in what it returns and that it's a required field, this next field. So these options are going to be the agents, the members of the team right now, researcher, encoder. But you could add other agents here. And that basically will enforce all this structure when we pass it to OpenAI will force the system to respond with one of these things because it's the required field and it has to be one of these things. And that's very, very useful. Rather than trying to prompt and argue with it to say, like, please, please, please don't ever respond with anything else, you know, instead of that, we can actually enforce it. So that's what's going on here. And that way it's deterministic in its selection. Well, it's not deterministic in what it selects. It still gets to choose freely between these two, but it's deterministic in that it has to follow this schema. This is all put together. And then the intermediary, when it's not the very first question, we tell the supervisor, hey, here's the conversation so far. Because basically that's what the work history is. It's a conversation of the past agents between each other and with themselves. And we ask the supervisor, hey, given this conversation, are we done or should we route it to somebody else? Put it together as a chain, actually. So even though we're using graph structures, the supervisor can be thought of as a chain. And then to actually make the graph, we need to represent the state. The state is a type dictionary, which really is just messages. So this almost could be a message graph. But we're also keeping track of what agent should be passed to next. So that's, that's what the next field is, and that's what keeps, that's what is being passed around by the different LLM nodes to each other. Then we can instantiate both the agents with the helpers we have. We can run Create Agent and say, hey, give it the web search tool and say, you're a web researcher. And we can run Create Agent and give it the Python tool and say, hey, you write Python code. And that gives us these agents. And then there's a little bit of functional programming paradigms going on here where, well, what is a node a node is. Whereas the agent node a node is this agent node function partially evaluated. So we're passing the agent to be, to do the execution and the name of it. But what we're not passing, we're not passing the state. So the result of this partial evaluation is a function that has two of the three parameters hard coded, but the third parameter, state, is open. And so now this truly is a node. This is a function that takes state and returns state. Same thing for the coder. And then similar to the MVP example, we've got to add the nodes to a workflow. The workflow though, is a state graph based on the state schema. And then we need to add edges. Everybody has an edge to the supervisor, and then there's conditional edges mapping from the supervisor to the other places. So everybody always goes back to the supervisor when they're done. Supervisor gets to decide what happens, compile the graph, and now we can invoke the team. And if we invoke the team, we can see here that call hello world and print it to the terminal. The supervisor says, well, hey, that should go to the coder. And then the coder execute some arbitrary code and says that they printed it. And the output here is a little bit funny looking, but MVP example. And now we can actually set a recursion limit and say write a brief research on picas and that gets mapped to the researcher, right? And now the researcher. So the LLM is routing to different agents and then giving us the responses. And right now both these examples just go to a single agent. I leave it to you to experiment with this more and come up with some prompt that maybe routes it more back and forth that requires collaboration of the agents, that kind of thing. But we are at or slightly past time, so I'll do one last pass for in the question thread here. And Ash, if you have anything you need you'd like to add.
Speaker A

Yeah, so the only thing I'd like to add is that on Monday we'll be doing agents as our next class and then followed by getting into the nuances of different tooling for that as well. So this is obviously a completely new concept and I want to start off by saying when you're building your AI components for your CRM, you don't have to use LangChain. We are using LangChain as an educational teaching tool because we feel it's a really nice way to illustrate what the possibility of a framework is. This means that you want to use Llama Index, go for it. If you want to use Auto Gen, go for it. If you want to use LangChain, go for that. You want to use Lang Graph, go for that. And if you want to make your own framework for the individuals who are so inclined, you can do that as well. The goal is to understand that these are the design patterns of how agents are being built right now. And the goal of today's class was do I understand those design patterns and can I make the basic agent? That's my first point. My second point is going to be that using langsmith is really, really, really important. When it comes to Lang Graph or using Lang Fuse and some of the other frameworks, you really need to see how your agent is working in the background, otherwise it's really hard to picture and like troubleshoot where it went wrong. So that's the other tip I'll give use Your langsmith wisely, you will be able to see exactly the decisions your supervisor is making, and you'll be able to see what's going wrong and what's working.
Speaker B

And we. We had our traces going here too. So there are a couple of questions in the thread that I'll tackle real quick. Do you tell the agent what tools it has in its prompt? That's something we'll discuss more on Monday. But the tools are passed along. Certainly the agent does have to know it's not necess. I don't think you necessarily describe them in the prompt, but it could be wise if the tools are a little confusing. But you can also there are certain approaches where the tools. Because the tools are functions, the functions have names and doc strings that can also inform the agent what the tool does. And default cases. State just grows and grows over time, possibly. I mean, it can also just update. Right? It doesn't have to grow that much. And realistically I'd say it's the message history that grows far faster than the state in most of these examples. Although, I mean, the state has message history in it. But like it's really. We're talking about message history handling. Right. Which the good news is that's a problem a lot of people have worked on. And so there are some good existing solutions to that for the most part. And usually the state outside of the message history is either not that big or is something that maybe you can also store elsewhere. If it really is big. Like you could have a tool that lets your agents access a database. Right. So anyway, thanks, Aaron. Sure. I think I caught all the questions in the thread. Are there any other questions? Again, I do encourage looking at these other notebooks as well.
Speaker A

And I will say that a large part of this is also. You guys will have to study the syntax on your own. It's not easy. You're not just going to pick up line graph like this. We'll be going through it multiple times. But feel free to use AI. I always like to start with that. So AI is a very powerful tool to get at least the gist of what you're building out there. And that's what your hiring partners expect of you. Right. So feel free to turn on Work Smart and start studying Lang graph. Like that is something that we fully expect you having to do. And obviously we'll be adding more and more classes and getting more and more complex as the weeks go on. That's it for me. I mean, Aaron, did you have anything to add?
Speaker B

That's it for me. Too. So thanks everybody.
Speaker A

Thanks everybody. I'm going to just call out some of the scheduled events for today. There's a project to check in today with me just, just for anybody who's having trouble understanding, like what AI components to build issues that you may be facing more from a design perspective, not from a engineering perspective. And then we have an office hours tomorrow to handle more of your full stack questions, errors that you're facing, etc. And then we have our logistics meeting tomorrow to handle your questions about moving to Austin, all those areas. And then we have a talk tonight with the founder of EV Every. His name is Kieran. He's awesome. So I just want to call out these events, make sure everyone's on the same page regarding these events. And if there's any questions, please, please let me know. But I hope everyone has a great day. I hope you guys get a lot of coding done today and I hope you guys study Lang graph a lot. So thank you again and I'll post the recording shortly. Bye, guys.
Speaker B

It.
