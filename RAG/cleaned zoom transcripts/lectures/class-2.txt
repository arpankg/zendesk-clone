%START_METADATA%

Class_Name="Class 2 - Brain Lifts and Spikey POVs"

Class_Date="2025-01-08"

%END_METADATA%



---

Speaker A

I've got to authorize it to record.


---

Speaker B

I just did.


---

Speaker A

Cool. Sorry about my cough, but yeah, as folks filter in, we're gonna go ahead and kick off and talk about some really, really exciting stuff. I'm gonna share my screen and make sure I've got the right Chrome that I'm sharing because I've got a handful of them. And we're going to jump back and forth just a little bit. All right, so today we are talking about BrainLift. So we'll get into all the details about what a BrainLift is. But the simplest way to think of it is it is a second brain, both for yourself. So you know, all of your learnings, all of your notes, all of you know, anything that you're going through, you'll record in a, you know, so that you have it and can. It's indexable, it's searchable, it's all of that fun stuff. Excuse me. And importantly for AI, so we not only build this second brain for ourselves, but we feed it to models in ways that are really cool and really exciting and really impactful.

But we feed it to models in ways that are really cool, really exciting, and really impactful. So we're going to go ahead and get started, and there are a couple of different pieces of software that you're all going to get access to. Actually, this is the wrong deck. And yeah, we'll get into all that. All right, so today we're going to talk about what LLMs are really good at, what they're bad at, and to some extent, how we override them. So LLMs are really, really good at giving us the consensus. Right. They've crawled the entire Internet. Every piece of data that there is to feed into these models is, if it's not already fed in, going to be fed in. The LLMs get really smart at telling you exactly what you would find if you were to summarize everything on the Internet. To some extent, that's really cool. But also, sometimes what is generally accepted on the Internet is wrong.

But also, sometimes what is generally accepted on the Internet is wrong. And when we talked about in the handbook the two things that are necessary to build really great products, we talk about BrainLift and we talk about AI-first development. So AI-first development, that's being able to build stuff really fast, really well, the spiky points of view, BrainLift, that's all about having a unique perspective, having a unique understanding. There's stuff that AI can't do and getting really good at doing the stuff that AI can't do. And this is where human reasoning and intuition and everything else that humans are really good at come into play. So we'll talk a lot about spiky POVs or spiky points of view. That's basically a non-consensus. Something that's not out there in the ether or accepted by an LLM is a pretty good definition of it. Before, you had to try to explain what the consensus view of the world was. Now it's like it's what the LLM thinks.

Now it's like it's what the LLM thinks. And then we're going to talk about how to use all of that to make LLMs better, make our understanding better, and we'll show you some really cool tools that really only exist within GauntletAI right now. But yeah, that'd be awesome. All right, so consensus views, when we say consensus view, what does that mean? One way I think of this is it's not exactly true, but if you were to ask Reddit, or if you were to ask Twitter, what's the general response going to be? Usually, it's not bad. Right. But it's not going to be surprising, and it's not going to be super valuable. So good leaders are strong communicators. Yeah, for sure. You would find that more so, you know, leaders have to have vision, leaders have to be decisive. That's all stuff that you would find if you were to ask an LLM what are the good traits that make up a leader. But obviously, there's a lot more to that.

But obviously, there's a lot more to that. And depending on how you're thinking about it, there are a lot of different angles and alternatives to understanding what a leader might be that might be really important. And we'll look at some examples of spiky POVs. We have a lot of them within Gauntlet. The reasons we run many things the way that we do, very, very different than what's commonly accepted, is because of that. All right, okay. Just making sure I'm keeping up with the chat. Yeah. So I would not want to live my life by asking Reddit what I should do in every instance. Not saying that everything on Reddit is incorrect, but that's not going to lead you down the optimal path. So some of this is about learning and making use of our knowledge. Some of it is about finding unique insight. Basically, any successful person or any successful company that you look at, they're going to have a bunch of spiky POVs that drive their success.

So Amazon, in the early days, wanted to offer a ton of selection. They knew that people would buy stuff on the Internet even without touching and seeing it. That was not the consensus at the time. Tesla started selling cars without dealerships. I mean, among these are the spiky POVs that these folks have. People want to share stuff that's going to stay forever. So those core concepts, those spiky POVs, are really what differentiate products and really the things that determine who you are in, I think, the most intense way. They're probably the most important. There's a bunch of consensus stuff like, hey, I need really good design. Very few places disagree with that, but the spiky POVs are what drive your products to really be great. So, yeah, that's where the innovation lies. It gives you a competitive advantage, and it's important not to be wrong where you can. I know that's easier said than done, but that's the reality of it.

I know that's easier said than done, but that's the reality of it. We're going to skip through a little bit of this, but, yeah, we've talked about how LLMs are really, really good at consensus. They excel at summarizing stuff. They are not good at everything. And we're going to have to spend a lot of time talking about where specifically LLMs are not good. More importantly, a lot of the time, you'll have to battle your LLM to some extent. If you just tell whatever AI model you're using, "Hey, remember that I think X once," it's going to revert back to the consensus again and again just because there's so much data and so much training that falls into that consensus. So we're going to strategically override some of that to get what we want out of the output. Sometimes that's just related to spiky POVs. Sometimes that's more like, "Hey, I know you've been trained on a million lines of JavaScript that say X. I'm not trying to do X right now; I'm trying to do Y."

I'm not trying to do X right now, I'm trying to do Y. So I know that, you know, you're trained to give me this. I need you to give me that instead. And you'll find that LLMs are always reverting back to the consensus, and it's a somewhat constant battle. We'll talk about how specifically to do that. All right, so one of the tools that we use to do that is called a second brain. So Thiago Forte was kind of the creator, at least the modern creator, of the second brain concept. All that a second brain is, is anything that you read or see or hear or touch, trying to get it into some format. In the early days of second brains, it was just so that you could have it, right? It was, hey, you know, as you're reading on Kindle, if you highlight it, you're going to automatically sync all of your notes to Evernote and then you can look it up. And then when you're reading an article on the Internet, if you use Instapaper, highlight it and it'll sync it to Evernote.

And so you have this giant library of everything that you've read, and it's indexed, and you can search it. That's kind of how it started, and that's still valuable. I'll show you in just a second. I've been using Roam Research for several years, and I have a giant, you know, five-year history of most of the meetings I've been in, most of the books that I've read, most of the articles that I've read. Generally speaking, the best second brain tools nowadays are built as a graph database. So stuff links together, and you can explore all the links. As an example, the visualization isn't useful other than it's interesting. But this is my Roam Research graph. So each one of those little nodes, as you're going through and taking notes, you can tag stuff, and it'll tag all the stuff together. Up here, those might be all the books that I've read. They might be tagged by the author.

Up here. Those might be all the books that I've read. They might be tagged by the author. And then if I'm reading a different book by a different author, I can jump to all the insights from that author. I can search for any word and I can find anything that I've read about that specific word. I can, you know, if I'm looking up Elon Musk, I can see all of the stuff that I've read about him in articles and biographies and all the tweets of his that I've saved and whatever else. So we're going to give you a second brain tool that everybody's going to use at Gauntlet, and we're going to show you how to use it in just a second, I think right now. So the tool that we use is called Workflowy. We use that specifically because there's some cool stuff that we've built into it. So there's a lot of different software that works, generally speaking, for a second brain. But for Gauntlet, we're all going to use Workflowy. You all have a premium Workflowy account.

But for Gauntlet, we're all going to use Workflowy. You all have a premium Workflowy account. Again, you have to register with it, but if you register with your GauntletAI.com email address, it'll automatically upgrade you to freemium. We're going to talk about BrainLifts and talk about how those work, but first we're going to look at Workflowy and see how that works. Obsidian is another great tool for that. Obsidian is great. Roam is. Yeah, I like Roam. But for this, for everything in Gauntlet, we're using Workflowy and we will show, yeah, I'll show you the export features. Workflowy is really, really good. So let me show you Workflowy real quick. Got to stop share. I've got to share my other Chrome window. This is Workflowy and what I've got right now is the generic template that it brings up as soon as you create a Workflowy account. It's an infinite document. Every bullet is also its own document. We'll show you what we mean by that. It's generally used as kind of an outline.

We'll show you what we mean by that. It's generally used as kind of an outline. So if I want to create a sub-bullet, I hit enter, and that goes to the next line. I hit tab, and now this, what I'm typing right here, is a child of the parent. That is that bullet. Right. So that makes sense. They're nested. Each one of these lines becomes its own document effectively. So I can open it up, and I can look at just that and its children, or I can go back and look at everything. So if you click on a bullet, it'll zoom into that specific bullet. If you click an arrow to the left, it'll expand and collapse. You can just type wherever you want. Enter creates a new bullet, tab will indent, shift + tab will outdent. So make it go back and forth between what level it is. You can use tags. There are a couple of different kinds of tags you can use. This is one kind of tag. If you use a hashtag-type tag, now you know, you can go and look at the page of everything that includes that hashtag. You can use today.

You can mark stuff with dates, you can share easily a bunch of keyboard shortcuts. And I think it's, you know, it'll become pretty obvious how to use it. And importantly, you can look at any sub-bullet, you can easily share both by email or secret link, you can export. Where is that at? You can export. It allows you to export in all sorts of different formats. And yeah, so that's Workflowy. That's the 30-second description of it. You'll get really used to using it. It's really powerful. It's really cool. I think that is pretty self-explanatory. Now we're going to talk a little bit about BrainLifts. All that a BrainLift is is it is a Workflowy document with a very specific format. And we'll talk about why this format is specific, but it is specific for a reason. So this is. I'm going to collapse everything before we look at this BrainLift. And as you've already seen, we're going to have you submit a BrainLift along with each product.

. And as you've already seen, we're going to have you submit a BrainLift along with each product. And that BrainLift consists of all the stuff that you're studying, all the stuff that you're reading about the product, about how AI is used to build that product. And in just a second it'll make a whole lot of sense why that's valuable. So this is the general BrainLift template. It has purpose events, spiky POVs, and knowledge tree. And you can create a template in Workflowy so that every time you create a BrainLift, you're just copying the template again and again. And then within the purpose, you're talking about why the BrainLift is going to be useful, what's in scope, what's out of scope. This is kind of all freeform, whatever you want to put in. And I guess I'm not going to bury the lead here.

And I guess I'm not going to bury the lead here. The powerful thing that we're going to do with all of this is we've built software that translates your BrainLift into an LLM so that the LLM understands and uses your BrainLift to basically alter itself. And we'll show you that software in just a second. There's a whole bunch of other stuff the software does. So you plug in some experts. Experts are people that you trust on this topic. And then within those experts, you can basically leave any of their views, you can write it out in text. Even more powerful is if you link stuff. So here we're going to look at what happens when this is the case. So here's. And I didn't build this BrainLift, so this is something that I know nothing about other than what's in here, which is a good way to think about it because that's kind of how your model views the world. So this is Kimberly Barron's. That's who she is. This is what's interesting about her.

So this is Kimberly Barron. That's who she is. This is what's interesting about her. Here's a link to her Twitter, here's a link to her website, here's a link to some other stuff that she's done. The more you know, if you can link directly to a website or to the resources that you want the LLM to learn from, it's going to absorb all of that and understand it, which is really difficult to wrap your mind around, but really, really cool. And then the spiky POVs we call out specifically as their own objects, and we do that as truths and myths. So you'll type those out, you can give some. These are some examples of truths and myths that they gleaned from the study of this topic, which I think was how to build the best vocabulary study for K through 8 schools or something like that. And so there are some of their spiky POVs about learning science. There are some of the myths that they are rejecting about learning science.

There are some of the myths that they are rejecting about learning science. And these are really, really important, these spiky POVs here that are going to override the default behavior of your LLM. If there's something that you want to be included in your thinking, in your product, in anything, if it's in the spiky POV, it's used as the strongest signal for an LLM to understand. So as an example, the traditional teacher-in-front-of-the-classroom model is one of the worst ways to teach students. It's been used for 100 years because it's cost-effective. Students can learn more if they're building more stuff. I mean, there's a whole bunch of stuff in here. Direct instruction is the fastest way to get information into a student's brain, which is why we're doing it right here as fast as we can.

But if you were to ask an LLM, and I'll show you in just a second, what's the best way to learn, if it's not going to understand all this stuff, it's probably going to be, you know, if I think about what the consensus view on learning is, it's probably going to say experimental or what's the, you know, the gosh, what's it called, like self-discovery learning is going to be the best because students learn the best that way. And so every time you try to design something, it's going to design it in that way, which is awesome, except when you don't want that. The reason the people that put this together don't always want inquiry-based learning, which was the word I was looking for, is because it takes a lot of time and it takes a lot of motivation from the student to be digging into stuff themselves when they don't know what they want to learn. Necessarily, when they build educational products, they override that behavior, that understanding within the LLM.

So that the LLM is not always spitting out like, oh, you should do this in inquiry-based. So this is kind of how we teach the LLM. And then at the bottom, we include knowledge categories, and that's basically any other insights, any other sources, and you'll get very, very used to all of this. So here's an example knowledge summary for training LLMs, which is what we're talking about. Here are the different ways that LLMs can be overridden. Here are all the different sources of how you can look at that with the summaries and the links and insights. This is all pretty free form. The only important things are these four categories. If you include those four categories, then it's going to work, and the LLM is going to be able to learn from it and override its default behavior. I'm going to jump into the chat just so. Yeah, we're going to talk about how it's overridden in just a second. Yep.

Yeah, we're going to talk about how it's overridden in just a second. Yep. This will make my honest concern is it seems like a bunch of busy work. Just wait. Just wait. So why do we do all of this? Why do we spend... I mean, yeah, I think that's a really good question to respond to directly. Are we just doing this to record all of our learning somewhere? We would probably do that because it's valuable, because it is important to be researching and learning. But if it were just that, I don't care enough that I'm going to make you guys document stuff in a specific way and make you show it to me in a specific way. The purpose of this is not just to show your work. So we're going to look at another piece of software that you guys will have access to very shortly. A small disclaimer that the auth on this was built assuming Google and then we couldn't use Google because they didn't authorize us to have enough licenses fast enough.

So we're fixing that auth as we speak, and soon you'll all have access to Ephor. This is Ephor. It's a really, really cool tool that everybody is going to have access to. It is currently in development, so there were changes to it literally yesterday, and today features have been added, and there are going to continue to be features added. We'll show you some of the really cool things that it can do. So first, we're going to. This is a new chat that I completely cleaned, hasn't been touched by anything. We're going to ask, "What does Ephor mean?" So what it's doing right now is this is the kind of base case for usage of Ephor. It just ran that query through 14 different AI models, all of which you have access to by virtue of using Ephor. And it's going to spit out each of those models so that you can look at them in different ways.

And it's going to spit out each of those models so that you can look at them in different ways. Well, I didn't want it to include my BrainLift, but oh well, let's start a brand new chat that doesn't have my library and then we're going to ask it, what is Ephor? So it's giving us mostly the same answer that it looks like it picked up on the landing page of Ephor. A collaborative AI assistant. Let's try a different one. What does the word Ephor mean? The word Ephor refers to an official in ancient Sparta who acted as an overseer or a guide. So that's why Ephor is named Ephor. So that's the response from Llama. Llama 3.1. We'll look at Llama 3.3. There's Gemini. There's Mistral. There's Nova. There's Qwen. There's Gemini, there's Grok, there's different OpenAI models. There's v0, there's 4.0 Mini, there's Nova Pro. There's Sonnet. So you can run queries against all of the LLMs simultaneously. It spits back. These are all really fast, but it will show you what the different speeds were.

It spits back. These are all really fast, but it will show you what the different speeds were. And pretty quickly you'll be like, okay, actually, it's taking long enough that I don't want to use all of the models. Let's just run it against those. Or you can run it against absolutely everything. Use a little bit of caution here because obviously these queries can add up and get expensive if you're not careful. The default setting is the fastest models. If you are just doing something basic, you can use the fast models. If you're doing something more advanced, you can pick whatever model works for you. It doesn't show it very well with that query because it was really simple. But let's do a more complex query. What's a more complex query? I hate thinking of very generic ones. I'm moving to Austin on February 3rd and I'm interested in good barbecue restaurants. What are the five best barbecue restaurants? Wow

What are the five best barbecue restaurants? Wow. Barbecue near downtown Austin that are open past 10 am because not all of them are going to be open at 10 am and just we're going to select all the models. We're going to hit return and now you'll be able to see some of what Ephor is capable of. All right, so there's what Llama gives you. There is Mistral, there's Qwen, there's Grok, there's Gemini. And so you can see here the different amount of tokens that are used. You can see the kind of weights or temperature of how it's determining that what percentage of the response is a result of which aspect of the model. Here in Gemini, you can see that some of it's from the system prompt, some of it is from the conversation history, and very little is from the query. Different models will have different weights and different speeds of all of that. So you can get used to using the models here. This is really important. You can annotate

So you can get used to using the models here. This is really important. You can annotate. In other words, you can give a thumbs up or a thumbs down. I'm not going to do that just because when you thumbs up or thumbs down something, that's going to make the model specifically within this chat know that you approved of or didn't appreciate that particular query. It's going to give you more or less of the response to that query. This is really cool, not only because you have access to everything, but because you can compare them really easily. Most of the time, eventually, you'll pick one model and just use it. That's the multi-AI model way of using Ephor. Now we're going to jump into artifacts. Not all of the models use artifacts. Artifacts is just on Sonnet 3.5, but I could say create a web page that gives me the top five barbecue restaurants in Austin that are open at 10 a.m. Now I'm going to scroll up so we can look at that.

There's some things that Sana is going to do really well here. There's some things that it's going to do less well at, and we will watch that happen. So it's building that out right now in the artifacts panel. It's going to give me a preview of the thing that it just built out. We'll see if it works the first time. I'd say sometimes it does, sometimes it doesn't. Okay, we just generated a website of the top five barbecue restaurants in Austin. It looks like it did have some sense of all of those. But what if it didn't know everything about what all those barbecue restaurants are? We can control what sources we're using here. This is one of the cool things that's pretty cool about Ephor. You can say let's also use the web, and we're going to run a similar query again.

You can say let's also use the web, and we're going to run a similar query again. I don't know if it will change, but turning on the web as the context to use now, we've kind of done some stuff in the background so that Sonnet, we bake in a web search crawler simultaneously, and it can not only build all that stuff, but it can search the web in order to do that. And it will probably build an artifact, and then it's going to give you some web results simultaneously. So this tab here allows you to determine what context to use. And you've got your library, which we'll show you in just a second. You've got your chats. You can use all of your chats, or you can ignore the other chats. You can use the web. And we've built in a search for X. And when I say we, I didn't build this, but people built it for us. So we're super, super grateful for them and for their work. So let's see what that web page looks like. Pretty similar. It didn't change too much. But just know that you can

Pretty similar. It didn't change too much. But just know that you can. It looks like here are some websites that it used to determine that. So those are the sources that it included. Now, we started this talking about BrainLift. Why are we talking about BrainLift in the context of Ephor? In using all of this stuff, I'm going to create a new chat and we're going to make the chat K through 8 education. And our goal is going to be models. We're going to include our library this time. We'll show you why. We'll do the fastest models and we'll show you what that is in just a second. Oh, that didn't name my chat. So what is going on here, by the way? You can attach documents, you can attach files. We're making it really easy to load stuff into a model. But if I go to project resources over here for this project, there is a data type of BrainLift. I'll show you how this works. But I've already done it. Here's another example of a BrainLift.

I'll show you how this works. But I've already done it. Here's another example of a BrainLift. Where is it anyway? So you can take this BrainLift and you say share. I only have view access to that one. So let's create a new BrainLift. I only have view access to that one. Okay, let's create a new node. Some BrainLift. When you're ready to move your BrainLift over to Ephor, all you have to do is hit share, click invite by secret link and copy this link. I just copy that link. Now I can go and pull over into Ephor. I've already done that, but I'll show you what it looks like. When you do that, you drop in your link. I have to do it again, sorry. You drop in your link, you say add. Now it's got that in the file. It knows that the type is Workflowy. I don't think I added that as a BrainLift though. There we go. Now the BrainLift has been loaded into the LLM. It's got all the truths, it's got all of the myths. There is a whole bunch of other stuff happening in the background.

There is a whole bunch of other stuff happening in the background. Now when I use my model, what is the best, fastest way to build a vocabulary lesson for K through 8 students? So it's going to, that was probably a bad prompt, but it's going to run through all of the models, but it's going to do them factoring in and weighing the BrainLift that we just used. So the more context you give the LLM, this lets you override the LLM's basic assumptions, basic theory, basic consensus. And we don't want X, we don't need web, we'll just do the fastest models. And I'm going to say produce a lesson plan for 8th grade vocabulary words including 50 of the best vocabulary words to use to prepare for the SAT. And I'm going to give it web search because it's probably going to go out and search the web for what are the 50 best vocabulary words to prepare for the SAT.

And then importantly, instead of just giving me a lesson plan, it now knows based on my spiky POVs, based on my BrainLift, what I'm looking for when I want a lesson plan. So it's going to give me stuff that it's all of that stuff that we plugged in that's non-consensus. It's now affecting the query that we run. And if we were to tell it to build a web page, the stuff that we loaded in would affect the webpage it builds. If it was code-based stuff, it would affect the code. So all of it matters. And you can pretty easily add different resources to your project. You can add different files, you can link different stuff. There's a bunch of stuff that it's pulling in within the BrainLift already. You can tell it how to prioritize different sources that you have loaded in. You can focus, you can increase prioritization, you can decrease prioritization. You're going to get used to all of this stuff. But this is a really, really powerful tool.

You're going to get used to all of this stuff. But this is a really, really powerful tool. And so yeah, it looks like as an example, Llama is giving us a very basic outline. If we go over to v0, it gives us a little bit different of one, and it's given us the 50 vocabulary words to use, and here are the sources that it pulled that from. So I'm going to jump into the chat because I know there are a whole bunch of questions happening, and I'm way behind. So give me just a second to scroll. Yeah. So will we lose? So Ephor is at. All the companies that are hiring from us use Ephor and use BrainLift and use Workflowy. That's the reason we're using those tools. But it will be probably a paid product at some point. I don't know the details of when as far as that goes. Okay, that's a good question from Mike. Does it aggregate all of the answers? No. At least not in this format. We'll show you some other stuff that it can do. But generally speaking, these are the responses.

We'll show you some other stuff that it can do. But generally speaking, these are the responses. It's running those all through each of those different models and telling you what the response is from all of those different models. Yeah, there is a compare view. So if I pick this model, how do I select multiple models? I think it's command. So I pick those three. I hit compare view and now it kind of breaks it down into different parts so you've got the summary from each of them. These are the elements that are unique to those different models. And then it kind of chunks it up into different categories and you can look at them independently and see really quickly. Okay, I like this. I don't like that you can get rid of models. It'll bring others in. Pretty freaking cool stuff that they've built for us. Oh, sorry, I should have showed you. That was a feature that wasn't there yesterday. Edit columns was not there yesterday. Oh yeah.

That was a feature that wasn't there yesterday. Edit columns was not there yesterday. Oh yeah. So you can pick and choose which models you're comparing just like that. And we didn't. Awesome. Pretty cool stuff. Yeah. Right now, the artifact page, it's not a great way to get stuff in and out of this. Outside of copy-paste, there's some other stuff that's going on for making it more advanced, for pulling it directly into a document. But for right now, you should use it purpose-built. If you're just building a generic application, you don't need this as much. If you are more doing stuff that's directly affected by your spiky POVs or you want to think about stuff a little bit differently or you want to test a bunch of models, use Ephor. There's a couple of other modes that I'll show you really quickly, reasoning that just uses the models that are really good at reasoning. Oh one, stuff like that, artifacts that build stuff for you.

Oh one, stuff like that, artifacts that build stuff for you. Multi AI models is the one we've been looking at where it looks at all of the models, and now let's look at Council of Kings. So this is kind of fun. The kings are, well, what's the best way to build a business? The reason this started is no. Okay, so we've got 10 experts that it's consulting, and we plugged in a couple of experts in learning science. And then it's got some generic experts. So we've got Lulu Chang, who is a corporate communicator. That's a generic one. Sam Altman is a generic one. You've got the Council of Ephors, which is if you try to aggregate all of the advice. I think we've got Warren Buffett in there. Zig Engelman is an education activist. This is my favorite one, Danielle, who is somebody who's helping us build out Gauntlet. You'll meet her in Austin. We plugged her in as a default king. So you can check out what her advice would be.

We plugged her in as a default king. So you can check out what her advice would be. And you'll love Danielle when you can meet her, and you still have the compare view. It's not pulling in the messages. And then I can say, hey, I liked Ziggs. That was good, I guess. Yeah. All right. You guys are arguing about. Yeah, I, I, I actually very legitimately, I mean, they're just barely getting started with this. This will become a $100 million product if they decide to launch it. Why can't I just paste my spiky POV from Workflowy combined with my prompt and say, consider my spiky POV? It would make a lot of sense if LLMs work that way. They don't always do that in the way that you would want. They tend to underweight your copy-paste stuff. You're always trying to. If I go back to actually the template that we were using for the BrainLift, there are a bunch of different ways to train LLMs. They can be overridden in the following ways: fine-tuning, RAG, context, and self-evolving.

They can be overridden in the following ways: fine-tuning, RAG, context, and self-evolving. So, context we like where we can provide it. RAG is a little more intense. Fine-tuning needs a ton of data. What's happening in the background of Ephor is a little bit of RAG, a little bit of context. You're injecting a little bit in the context window and then you're trying to vectorize some data and feed it into the model and say, use this. So you can do that with your data. You can just copy-paste. I'm not opposed to that at all. Generally speaking, this will override harder if you use Ephor than if you're just copy-pasting into the direct context window. The one thing that I do want to make clear about all of this is none of this existed a month ago. So there is a lot of learning, there's a lot of change that's going to happen. There's going to be a lot of enablement. I'm sure there are ways we'll learn that the tools work well.

I'm sure there are ways we'll learn that the tools work well. There are ways we'll learn that the tools don't work well. But yeah, that's a really good question. Are the models being trained on our BrainLift? So let's talk for just a minute about the word trained. Because there are different definitions of the word trained. And the proper definition of trained is when you're building a model, you're training it on a bunch of data and then everything that we do on top of that technically isn't training a model, but it's kind of informing a model. Sometimes I'll use train versus inform. It's one of those things that a lot of people use those words synonymously enough that they've lost a whole lot of meaning. People will say you're training a model here even though we're not taking it directly. Some other cool stuff that you can do if I go to Experts feed, sorry, Experts feed it is. It's taking everything from my BrainLift, including the experts that I plugged in.

It's taking everything from my BrainLift, including the experts that I plugged in. It's deducing who other experts might be based on who those people are. And if you want to learn really quickly about something, you can go to your experts feed on any given project, and it's going to give you a sense of who it thinks the experts might be on X. You can follow them, you can engage with those people. So Tommy Lee is a guy who talks about education a lot. Looks like that is Synthesis, which is an AI tutor that my kids use. Yeah. Not all of this is going to be directly relevant to what you're building, but it helps you identify the people that you might want to follow and the people that you might want to learn from. There are metrics tabs that are going to kind of graph out your LLMs, which ones are the best, which ones are the fastest, which ones you're using a lot, and let you determine what you're looking at.

If you're just looking at today or the last seven days, a bunch of other cool stuff you can use multi-user chats, you can share these or invite other people. We probably won't be doing a ton of that very quickly. Yeah, there are a couple of tools. So some of the questions I'm already seeing are, does this tool work reliably on Workflowy docs in other languages? Well, here's something about AI that's interesting. I have no idea because I don't know that anybody has ever tried it. Normally in software land, you would say no. It would be ridiculous that you would expect software to automatically be able to understand different languages. It is entirely possible that it does. I just don't know. Is RAG only as good as the BrainLift we connect to Ephor? I know you're going to hate me for this. I'm not going to get deep into RAG and how it works and all the benefits because that's the next that's coming later. And we could talk about RAG for hours and hours and we will.

And we could talk about RAG for hours and hours, and we will. RAG is retrieval-augmented generation, which is a methodology for feeding models data. What is access like for reasoning models? So, yeah, reasoning models. If I go back to my chat over here and hide my metrics, hide my Experts feed. Sorry, I've got a bunch of Zoom windows, so it's hard for me to see everything. I hide my Experts feed, go back to chat. There we go. So the reasoning models, you have 0101 mini and Gemini 2.0 through Ephor. Cool. Yes. It uses the. For the experts. We have experts here. So we plugged in Zig Engelman, Kimothy Behrens, and Justin Skykak, and then if we were to ask. If we were to go to. I think it's Council of Kings still getting used to the interfaces. There's Zig Engelman. It won't load somebody if it can't find enough on them. And it plugged in Benjamin Bloom as well. So yeah, you list those in the BrainLift.

And it plugged in Benjamin Bloom as well. So yeah, you list those in the BrainLift. Yeah. You'll have a lot of time to play with this, so please keep building and don't just sit here and play with it all day. But obviously, playing with AI is a good thing. Yeah. What qualifies as an expert? I think the way I would define an expert is it's somebody that you trust to have a good opinion about X. So even if someone is, you know, widely regarded as an expert, if I think they're an idiot, I would not include them as an expert in Workflowy. And one of the things that you'll find is your judgment really matters when you're doing stuff like this at companies that are using BrainLifts. What is in the BrainLift really matters. And it's actually a really good forcing function for if you disagree with something in the spiky POVs. As an example, I think if you were to look at a company's spiky POVs, that becomes the culture, that becomes the way a company operates.

If people are disagreeing about the spiky POVs, there's nothing that guarantees that what's in your spiky POVs is correct. You could be wrong, you could be misguided, you could be misunderstanding. It's really important that you are correct or that at least it doesn't break everything if you're incorrect. And so if you're building a group project and you disagree about the spiky POVs, those are really, really important conversations to have. And having talked to some of the folks that are using this framework as a company, those force to the forefront conversations that are really, really important to hash out. And sometimes it's the same as any other company, sometimes it's disagree and commit. You know, just the fact that you're writing stuff down isn't going to naturally solve all of your questions. But yeah, does it matter if we talk about Ephor online? I think you're fine to talk about it. You should be fine there. Yeah. I don't know a ton about multi-language tasks.

You should be fine there. Yeah. I don't know a ton about multi-language tasks. I speak Russian, but I haven't plugged anything in, so I don't know, I haven't. I mean, there are a whole bunch of experiments that I'm like, one of the cool things about having, you know, 100 plus people that are trying all this stuff is I'm sure someone's going to stumble upon something interesting or a clever hack or different ways to use all this stuff. And yeah, we'll learn a lot from each other as well. All right. I think my spiky POV is that NextJS is bad. Yeah. Well, you can plug that into your spiky POVs and your LLM will be less likely to write NextJS if you think it's bad. Yeah. And we'll talk a lot about RAG and embeddings and context windows and other technical stuff that we don't have time to get into yet. But we wanted to introduce this to you and that gives us a chance to actually use spiky POVs and BrainLifts for the first time.

So as a part of your final submission on Slack, that's going to happen on Friday. The reason we do that on Friday is because most of you are going to have some things that we're going to strongly recommend you fix over the weekend, or you can keep working on them over the weekend. I think I get it. But before you finish, can we get an elevator pitch for why these tools deserve a spot in our workflow? So look, if you decide not to use Ephor, that's totally fine. I'm not going to ever be like, you have to use this tool in this way. Other than that, when you submit your BrainLift, it has to be in Workflowy, because that's the simplest for all the software that we've built to understand; everything uses Workflowy. So Workflowy, I am going to take back what I just said. We're going to require that you use Workflowy. You don't have to use Ephor. I think it's a really cool tool, but I'm not going to force you to use it or monitor its usage or look at anything. If you have recommendations for it...

If you have recommendations for it, we talk with the team constantly. And yes, in the slides, there's a direct link to the Workflowy template. And you guys are going to get really used to BrainLifts and the template, but you'll literally get a list link to this exact BrainLift template. And we haven't talked a lot about sharing, but as you can imagine, if I drill into one of these bullets, I can export or share or load in just that bullet when the server is not encountering an error. There is a bunch of other stuff that you can do over here. You can mirror it, you can export it as markdown if you want to. But yeah, if there are any more questions, feel free to ask in Slack. I know this was a very direct introduction to Ephor. Oh, the other thing, we're still finishing up getting everybody Ephor access. We have to build in a new type of authentication. So that will be coming probably later today. Workflowy, the same as most other tools, is fully authorized with corporate-level stuff.

Workflowy, the same as most other tools. It's fully authorized with corporate-level stuff. If you sign up with a GauntletAI.com email address with that, we'll let you get back to extending your Slack projects. And Ash, go ahead.


---

Speaker B

Yeah, I had one thing to say. I keep getting the same question over and over again, which is like, what am I supposed to be doing now? The goal when you have free time is to work on your Slack project and make sure it has all the foundation to add all the AI features on top. You don't want to come into Monday and have to work, worry about threads, worry about channels, worry about random features that you were. You needed to then add AI to it, right? So you want to get this into a place where it's really nice, really working well, so that when you start adding AI and it starts to hallucinate and it starts to get much harder and it becomes much more difficult for you to add these AI features. You don't want to worry about the easy stuff, you want to focus on the AI. So I just want to say that when you have free time, you should be working on making your foundation the best it can be. The AI features are outlined in the document if you just scroll to the bottom as well.

The AI features are outlined in the document if you just scroll to the bottom as well. But you guys can add the AI features you would like, as I just want to make that very clear. What should you be doing? You should be preparing your Slack project and making it the best it can be for Friday submission and readying it for AI tooling. Sorry. Thanks, Austin.


---

Speaker A

Awesome. Thank you, everybody. And yeah, are there any other questions? I think this is where stuff starts to get really interesting, and there we are. I can't believe it. This is day three, so we've only gone through 48 hours of the 90ish days of Gauntlet so far. There's a whole lot more, but I think you've got a pretty good jumping-off point to build your first project. And I would echo what Ash recommends: building existing. You want your Slack clone to be as feature-complete, productized, and pushed to production as it possibly can be. And yeah, it definitely feels like Friday already, and we're going to work until then. Next week gets much deeper into the stuff that wasn't, I'll say, stuff that wasn't possible until a couple of years ago. So we're really looking forward to that. Thank you, everybody. And we'll be on Slack.
